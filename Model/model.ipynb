{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\thinkbig\\desktop\\formative_databases\\model\\myenv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\thinkbig\\desktop\\formative_databases\\model\\myenv\\lib\\site-packages (from pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\thinkbig\\desktop\\formative_databases\\model\\myenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\thinkbig\\desktop\\formative_databases\\model\\myenv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\thinkbig\\desktop\\formative_databases\\model\\myenv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\thinkbig\\desktop\\formative_databases\\model\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "import requests\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ID', 'Country of Origin', 'Farm Name', 'Lot Number',\n",
       "       'Mill', 'ICO Number', 'Company', 'Altitude', 'Region', 'Producer',\n",
       "       'Number of Bags', 'Bag Weight', 'In-Country Partner', 'Harvest Year',\n",
       "       'Grading Date', 'Owner', 'Variety', 'Status', 'Processing Method',\n",
       "       'Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body', 'Balance',\n",
       "       'Uniformity', 'Clean Cup', 'Sweetness', 'Overall', 'Defects',\n",
       "       'Total Cup Points', 'Moisture Percentage', 'Category One Defects',\n",
       "       'Quakers', 'Color', 'Category Two Defects', 'Expiration',\n",
       "       'Certification Body', 'Certification Address', 'Certification Contact'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset (replace with actual file path)\n",
    "data = pd.read_csv(\"df_arabica_clean.csv\")\n",
    "\n",
    "# Show a preview of the data (uncomment if needed)\n",
    "data.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Features and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aroma</th>\n",
       "      <th>Flavor</th>\n",
       "      <th>Aftertaste</th>\n",
       "      <th>Acidity</th>\n",
       "      <th>Body</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Uniformity</th>\n",
       "      <th>Clean Cup</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Total Cup Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.58</td>\n",
       "      <td>8.50</td>\n",
       "      <td>8.42</td>\n",
       "      <td>8.58</td>\n",
       "      <td>8.25</td>\n",
       "      <td>8.42</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>89.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.50</td>\n",
       "      <td>8.50</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.25</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>87.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.33</td>\n",
       "      <td>8.42</td>\n",
       "      <td>8.08</td>\n",
       "      <td>8.17</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.17</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>87.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.08</td>\n",
       "      <td>8.17</td>\n",
       "      <td>8.17</td>\n",
       "      <td>8.25</td>\n",
       "      <td>8.17</td>\n",
       "      <td>8.08</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>87.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.33</td>\n",
       "      <td>8.33</td>\n",
       "      <td>8.08</td>\n",
       "      <td>8.25</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.92</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>87.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>7.17</td>\n",
       "      <td>7.17</td>\n",
       "      <td>6.92</td>\n",
       "      <td>7.17</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>80.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>7.33</td>\n",
       "      <td>7.08</td>\n",
       "      <td>6.75</td>\n",
       "      <td>7.17</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.17</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>7.25</td>\n",
       "      <td>7.17</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.08</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>79.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>6.50</td>\n",
       "      <td>6.75</td>\n",
       "      <td>6.75</td>\n",
       "      <td>7.17</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>7.25</td>\n",
       "      <td>7.08</td>\n",
       "      <td>6.67</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.67</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>78.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Aroma  Flavor  Aftertaste  Acidity  Body  Balance  Uniformity  Clean Cup  \\\n",
       "0     8.58    8.50        8.42     8.58  8.25     8.42        10.0       10.0   \n",
       "1     8.50    8.50        7.92     8.00  7.92     8.25        10.0       10.0   \n",
       "2     8.33    8.42        8.08     8.17  7.92     8.17        10.0       10.0   \n",
       "3     8.08    8.17        8.17     8.25  8.17     8.08        10.0       10.0   \n",
       "4     8.33    8.33        8.08     8.25  7.92     7.92        10.0       10.0   \n",
       "..     ...     ...         ...      ...   ...      ...         ...        ...   \n",
       "202   7.17    7.17        6.92     7.17  7.42     7.17        10.0       10.0   \n",
       "203   7.33    7.08        6.75     7.17  7.42     7.17        10.0       10.0   \n",
       "204   7.25    7.17        7.08     7.00  7.08     7.08        10.0       10.0   \n",
       "205   6.50    6.75        6.75     7.17  7.08     7.00        10.0       10.0   \n",
       "206   7.25    7.08        6.67     6.83  6.83     6.67        10.0       10.0   \n",
       "\n",
       "     Sweetness  Total Cup Points  \n",
       "0         10.0             89.33  \n",
       "1         10.0             87.58  \n",
       "2         10.0             87.42  \n",
       "3         10.0             87.17  \n",
       "4         10.0             87.08  \n",
       "..         ...               ...  \n",
       "202       10.0             80.08  \n",
       "203       10.0             80.00  \n",
       "204       10.0             79.67  \n",
       "205       10.0             78.08  \n",
       "206       10.0             78.00  \n",
       "\n",
       "[207 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the features (independent variables) and target (dependent variable)\n",
    "# data.columns = data.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "features = [\"Aroma\", \"Flavor\", \"Aftertaste\", \"Acidity\", \"Body\", \"Balance\", \"Uniformity\", \"Clean Cup\", \"Sweetness\"]\n",
    "target = \"Total Cup Points\"  \n",
    "\n",
    "# Keep only relevant columns in the dataset\n",
    "data = data[features + [target]]\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(data.mean(), inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Split Data into Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features X, and target y\n",
    "\n",
    "X = data[features]\n",
    "y = data[target]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Normalize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data using StandardScaler \n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaler, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check for NaN values in X_train\n",
    "print(np.isnan(X_train).sum())  \n",
    "\n",
    "# Check for NaN values in y_train\n",
    "print(np.isnan(y_train).sum())  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Train the Model with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n"
     ]
    }
   ],
   "source": [
    "# Initialise the XGBoost model\n",
    "xgb_model  = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "\n",
    "# Set hyperparameters for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'subsample': [0.7, 1.0]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=2, scoring=\"neg_mean_squared_error\", n_jobs=2, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model after tuning\n",
    "best_xgb = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Evaluate the Model and Save It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized XGBoost Model MSE: 0.1099621414331278\n",
      "Model and Scaler saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Optimized XGBoost Model MSE: {mse}\")\n",
    "\n",
    "# Save the trained model and the scaler for future use\n",
    "joblib.dump(best_xgb, \"coffee_xgboost_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"Model and Scaler saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.remove(\"coffee_xgboost_model.pkl\")\n",
    "# os.remove(\"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Fetch Data from API and Make Predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10.1: Load the Trained Model and Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model and scaler from the disk\n",
    "model = joblib.load(\"coffee_xgboost_model.pkl\")\n",
    "scaler = joblib.load('scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10.2: Fetch the Latest Data from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer_id': 1, 'harvest_year': 2022, 'grading_date': '2022-09-21', 'variety': 'Gesha', 'processing_method': 'Washed / Wet', 'aroma': 8.08, 'flavor': 8.17, 'aftertaste': 8.17, 'acidity': 8.25, 'body': 8.17, 'balance': 8.08, 'uniformity': 10.0, 'clean_cup': 10.0, 'sweetness': 10.0, 'moisture_percentage': 11.8, 'category': 'Arabica', 'quakers': 0, 'color': 'green', 'coffee_id': 1, 'total_cup_points': 78.92, 'quality_classification': 'Premium', 'created_at': '2025-03-13T19:39:48.424299', 'updated_at': '2025-03-13T19:39:48.424299'}\n"
     ]
    }
   ],
   "source": [
    "# API URL to fetch the latest data (replace with actual API endpoint)\n",
    "API_URL = \"https://api-endpoint-99oz.onrender.com/api/coffees/latest/\"\n",
    "\n",
    "# Send a request to fetch the latest data\n",
    "response = requests.get(API_URL)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    latest_data = response.json()  # Convert API response to JSON\n",
    "    print(latest_data)\n",
    "else:\n",
    "    print(\"Failed to fetch data\")\n",
    "    exit()  # Exit the program if data retrieval fails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10.3: Convert API Response into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer_id': 1, 'harvest_year': 2022, 'grading_date': '2022-09-21', 'variety': 'Gesha', 'processing_method': 'Washed / Wet', 'aroma': 8.08, 'flavor': 8.17, 'aftertaste': 8.17, 'acidity': 8.25, 'body': 8.17, 'balance': 8.08, 'uniformity': 10.0, 'clean_cup': 10.0, 'sweetness': 10.0, 'moisture_percentage': 11.8, 'category': 'Arabica', 'quakers': 0, 'color': 'green', 'coffee_id': 1, 'total_cup_points': 78.92, 'quality_classification': 'Premium', 'created_at': '2025-03-13T19:39:48.424299', 'updated_at': '2025-03-13T19:39:48.424299'}\n",
      "Index(['producer_id', 'harvest_year', 'grading_date', 'variety',\n",
      "       'processing_method', 'aroma', 'flavor', 'aftertaste', 'acidity', 'body',\n",
      "       'balance', 'uniformity', 'clean_cup', 'sweetness',\n",
      "       'moisture_percentage', 'category', 'quakers', 'color', 'coffee_id',\n",
      "       'total_cup_points', 'quality_classification', 'created_at',\n",
      "       'updated_at'],\n",
      "      dtype='object')\n",
      "Warning: The following features are missing in the DataFrame: ['Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body', 'Balance', 'Uniformity', 'Clean Cup', 'Sweetness']\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Print the structure of `latest_data` to check if it contains the correct feature names\n",
    "print(latest_data)\n",
    "\n",
    "# Convert the API response into a pandas DataFrame\n",
    "df = pd.DataFrame([latest_data])  # Assuming latest_data is a list of dictionaries\n",
    "\n",
    "# Print column names to verify if the features exist\n",
    "print(df.columns)\n",
    "\n",
    "# Ensure that the 'features' list matches the columns of the DataFrame\n",
    "features = ['Aroma', 'Flavor', 'Aftertaste', 'Acidity', 'Body', 'Balance', 'Uniformity', 'Clean Cup', 'Sweetness']\n",
    "\n",
    "# Select only the relevant features for prediction\n",
    "# You can also add a check here to see if all features exist in the DataFrame\n",
    "missing_features = [f for f in features if f not in df.columns]\n",
    "if missing_features:\n",
    "    print(f\"Warning: The following features are missing in the DataFrame: {missing_features}\")\n",
    "\n",
    "# Select only available features\n",
    "df = df[[f for f in features if f in df.columns]]\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10.4: Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the mean of each column\n",
    "df.fillna(df.mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 10.5: Scale the Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names\n",
    "df.columns = df.columns.str.title().str.replace(\"_\", \" \")\n",
    "\n",
    "# Ensure all required features exist\n",
    "for col in scaler.feature_names_in_:\n",
    "    if col not in df:\n",
    "        df[col] = 0\n",
    "\n",
    "# Reorder and transform\n",
    "df = df[scaler.feature_names_in_].astype(float)\n",
    "df_scaled = scaler.transform(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10.6: Make a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Coffee Quality Score: 78.05490112304688\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to make a prediction\n",
    "prediction = model.predict(df_scaled)\n",
    "\n",
    "# Display the predicted coffee quality score\n",
    "print(f\"Predicted Coffee Quality Score: {prediction[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
